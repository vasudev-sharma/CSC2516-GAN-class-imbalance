{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "# from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "path = \"/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='/local/nhulkund/UROP/Chexpert/data/CheXpert-v1.0-small/'\n",
    "train=pd.read_csv(path+'train.csv')\n",
    "label_cols=train.columns[5:]\n",
    "train[label_cols]=train[label_cols].fillna(0.0)\n",
    "train[label_cols]=train[label_cols].replace(-1.0,1.0)\n",
    "train[\"ID\"] = train[\"Path\"].apply(lambda x: x.split(\"patient\")[1].split(\"/\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patients, test_patients = train_test_split(train_shuffled[\"ID\"].unique(), test_size=0.1)\n",
    "train_split, test_split = train_shuffled[train_shuffled[\"ID\"].isin(train_patients)], train_shuffled[train_shuffled[\"ID\"].isin(test_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split.to_csv(path + \"train_preprocessed.csv\")\n",
    "test_split.to_csv(path + \"test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "\n",
    "\n",
    "def get_class_split(labels, proportion=True):\n",
    "    split = {}\n",
    "    total = len(labels)\n",
    "    for name in names:\n",
    "        split[name] = sum(labels[name])/total if proportion else sum(labels[name])\n",
    "    return split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GAN data to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + \"train_preprocessed.csv\")\n",
    "# test = pd.read_csv(path + \"test_train_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/gan_labels_65000_prop.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-08d1ea064c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"CheXpert-v1.0-small/train/patient65000/study1/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/om/user/shobhita/src/chexpert/data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"gan_labels_65000_prop.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgan_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/gan_labels_65000_prop.pkl'"
     ]
    }
   ],
   "source": [
    "base_path = \"CheXpert-v1.0-small/train/patient65000/study1/\"\n",
    "label_path = \"/om/user/shobhita/src/chexpert/data/\"\n",
    "with open(path + \"gan_labels_65000_prop.pkl\", \"rb\") as handle:\n",
    "    gan_labels = pickle.load(handle)\n",
    "\n",
    "gan_data = []\n",
    "    \n",
    "for img_id, label in gan_labels.items():\n",
    "    img_filename = \"fake_{}.png\".format(img_id)\n",
    "    img_path = base_path + img_filename\n",
    "    img_row = {}\n",
    "    img_row[\"Path\"] = img_path\n",
    "    img_row[\"Sex\"] = \"Female\"\n",
    "    img_row[\"Age\"] = 21\n",
    "    img_row[\"Frontal/Lateral\"] = \"Frontal\"\n",
    "    img_row[\"AP/PA\"] = \"AP\"\n",
    "    for i, name in enumerate(names):\n",
    "        img_row[name] = label[i]\n",
    "    img_row[\"ID\"] = 65000\n",
    "    gan_data.append(img_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_df = pd.DataFrame(gan_data)\n",
    "full_train_df = pd.concat([train, gan_df], ignore_index=True)\n",
    "full_train_df.to_csv(path + \"train_with_gan_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254510, 20)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gan = pd.read_csv(path + \"train_with_gan_preprocessed.csv\")\n",
    "train_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "names = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40439"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"ID\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train[\"Path\"].apply(lambda x: int(x.split(\"patient\")[1].split(\"/\")[0]))\n",
    "test_ids = test[\"Path\"].apply(lambda x: int(x.split(\"patient\")[1].split(\"/\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64540"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_ids.max(), test_ids.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid=pd.read_csv(path+'valid.csv')\n",
    "label_cols=train.columns[5:]\n",
    "valid[label_cols]=valid[label_cols].fillna(0.0)\n",
    "valid[label_cols]=valid[label_cols].replace(-1.0,1.0)\n",
    "valid.to_csv(path+\"valid_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample to 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/\"\n",
    "train = pd.read_csv(path + \"train_preprocessed.csv\")\n",
    "test = pd.read_csv(path + \"test_train_preprocessed.csv\")\n",
    "train_gan = pd.read_csv(path + \"train_with_gan_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_patients, _ = train_test_split(train[\"ID\"].unique(), test_size=0.5)\n",
    "train_subset = train[train[\"ID\"].isin(train_subset_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5007671643717941"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_subset)/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data = train_gan[train_gan[\"ID\"] == 64600]\n",
    "train_subset_with_gan = pd.concat([train_subset, gan_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_csv(path + \"train_preprocessed_subset.csv\", index=False)\n",
    "train_subset_with_gan.to_csv(path + \"train_preprocessed_subset_with_gan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio:  0.1011514913774697\n"
     ]
    }
   ],
   "source": [
    "path = \"/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/\"\n",
    "train = pd.read_csv(path + \"train_preprocessed.csv\")\n",
    "test = pd.read_csv(path + \"test_train_preprocessed.csv\")\n",
    "train_gan = pd.read_csv(path + \"train_with_gan_preprocessed.csv\")\n",
    "\n",
    "train_subset_patients, _ = train_test_split(train[\"ID\"].unique(), test_size=0.9)\n",
    "train_subset = train[train[\"ID\"].isin(train_subset_patients)]\n",
    "\n",
    "print(\"Ratio: \", len(train_subset)/len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No Finding': 2020.0,\n",
       " 'Enlarged Cardiomediastinum': 2018.0,\n",
       " 'Cardiomegaly': 3148.0,\n",
       " 'Lung Opacity': 10246.0,\n",
       " 'Lung Lesion': 927.0,\n",
       " 'Edema': 5898.0,\n",
       " 'Consolidation': 3818.0,\n",
       " 'Pneumonia': 2261.0,\n",
       " 'Atelectasis': 5931.0,\n",
       " 'Pneumothorax': 2260.0,\n",
       " 'Pleural Effusion': 8869.0,\n",
       " 'Pleural Other': 603.0,\n",
       " 'Fracture': 887.0,\n",
       " 'Support Devices': 10625.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = get_class_split(train_subset)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_csv(path + \"train_preprocessed_subset_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + \"train_preprocessed_subset_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100850"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 64900\n",
    "gan_label_path = \"/om/user/shobhita/src/chexpert/data/gan_labels_{}_prop.pkl\".format(patient_id)\n",
    "base_path = \"CheXpert-v1.0-small/train/patient{}/study1/\".format(patient_id)\n",
    "\n",
    "with open(gan_label_path, \"rb\") as handle:\n",
    "    gan_labels = pickle.load(handle)\n",
    "\n",
    "gan_data = []\n",
    "    \n",
    "for img_id, label in gan_labels.items():\n",
    "    img_filename = \"{}.jpg\".format(img_id)\n",
    "    img_path = base_path + img_filename\n",
    "    img_row = {}\n",
    "    img_row[\"Path\"] = img_path\n",
    "    img_row[\"Sex\"] = \"Female\"\n",
    "    img_row[\"Age\"] = 21\n",
    "    img_row[\"Frontal/Lateral\"] = \"Frontal\"\n",
    "    img_row[\"AP/PA\"] = \"AP\"\n",
    "    for i, name in enumerate(names):\n",
    "        img_row[name] = label[i]\n",
    "    img_row[\"ID\"] = patient_id\n",
    "    gan_data.append(img_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_df = pd.DataFrame(gan_data)\n",
    "full_train_df = pd.concat([train, gan_df], ignore_index=True)\n",
    "full_train_df.to_csv(path + \"train_preprocessed_subset_50_with_gan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan = pd.read_csv(path + \"train_preprocessed_subset_50_with_gan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100850"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147850"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CheXpert-v1.0-small/train/patient64900/study1/Lung_Lesion_0.jpg'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gan[train_gan[\"ID\"] == 64900][\"Path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample to 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio:  0.04991782155111202\n",
      "{'No Finding': 1036.0, 'Enlarged Cardiomediastinum': 1010.0, 'Cardiomegaly': 1485.0, 'Lung Opacity': 5117.0, 'Lung Lesion': 456.0, 'Edema': 2877.0, 'Consolidation': 2021.0, 'Pneumonia': 1096.0, 'Atelectasis': 3064.0, 'Pneumothorax': 1098.0, 'Pleural Effusion': 4381.0, 'Pleural Other': 324.0, 'Fracture': 338.0, 'Support Devices': 5379.0}\n"
     ]
    }
   ],
   "source": [
    "path = \"/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/\"\n",
    "train = pd.read_csv(path + \"train_preprocessed.csv\")\n",
    "test = pd.read_csv(path + \"test_train_preprocessed.csv\")\n",
    "train_gan = pd.read_csv(path + \"train_with_gan_preprocessed.csv\")\n",
    "\n",
    "train_subset_patients, _ = train_test_split(train[\"ID\"].unique(), test_size=0.95)\n",
    "train_subset = train[train[\"ID\"].isin(train_subset_patients)]\n",
    "\n",
    "print(\"Ratio: \", len(train_subset)/len(train))\n",
    "\n",
    "splits = get_class_split(train_subset, proportion=False)\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_csv(path + \"train_preprocessed_subset_5.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10053"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(path + \"train_preprocessed_subset_5.csv\")\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 65100\n",
    "gan_label_path = \"/om/user/shobhita/src/chexpert/data/gan_labels_5.pkl\"\n",
    "base_path = \"CheXpert-v1.0-small/train/patient{}/study1/\".format(patient_id)\n",
    "\n",
    "with open(gan_label_path, \"rb\") as handle:\n",
    "    gan_labels = pickle.load(handle)\n",
    "\n",
    "gan_data = []\n",
    "    \n",
    "for img_id, label in gan_labels.items():\n",
    "    img_filename = \"{}.jpg\".format(img_id)\n",
    "    img_path = base_path + img_filename\n",
    "    img_row = {}\n",
    "    img_row[\"Path\"] = img_path\n",
    "    img_row[\"Sex\"] = \"Female\"\n",
    "    img_row[\"Age\"] = 21\n",
    "    img_row[\"Frontal/Lateral\"] = \"Frontal\"\n",
    "    img_row[\"AP/PA\"] = \"AP\"\n",
    "    for i, name in enumerate(names):\n",
    "        img_row[name] = label[i]\n",
    "    img_row[\"ID\"] = patient_id\n",
    "    gan_data.append(img_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_df = pd.DataFrame(gan_data)\n",
    "full_train_df = pd.concat([train, gan_df], ignore_index=True)\n",
    "full_train_df.to_csv(path + \"train_preprocessed_subset_5_with_gan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14903"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4850"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample to 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  2050\n",
      "Ratio:  0.010179203638692891\n",
      "{'No Finding': 228.0, 'Enlarged Cardiomediastinum': 250.0, 'Cardiomegaly': 311.0, 'Lung Opacity': 1044.0, 'Lung Lesion': 134.0, 'Edema': 496.0, 'Consolidation': 343.0, 'Pneumonia': 244.0, 'Atelectasis': 571.0, 'Pneumothorax': 272.0, 'Pleural Effusion': 926.0, 'Pleural Other': 53.0, 'Fracture': 82.0, 'Support Devices': 1075.0}\n"
     ]
    }
   ],
   "source": [
    "path = \"/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/\"\n",
    "train = pd.read_csv(path + \"train_preprocessed.csv\")\n",
    "train_gan = pd.read_csv(path + \"train_with_gan_preprocessed.csv\")\n",
    "\n",
    "train_subset_patients, _ = train_test_split(train[\"ID\"].unique(), test_size=0.99)\n",
    "train_subset = train[train[\"ID\"].isin(train_subset_patients)]\n",
    "\n",
    "print(\"Size: \", len(train_subset))\n",
    "print(\"Ratio: \", len(train_subset)/len(train))\n",
    "\n",
    "splits = get_class_split(train_subset, proportion=False)\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_csv(path + \"train_preprocessed_subset_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2050"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(path + \"train_preprocessed_subset_1.csv\")\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 65200\n",
    "gan_label_path = \"/om/user/shobhita/src/chexpert/data/gan_labels_1.pkl\"\n",
    "base_path = \"CheXpert-v1.0-small/train/patient{}/study1/\".format(patient_id)\n",
    "\n",
    "with open(gan_label_path, \"rb\") as handle:\n",
    "    gan_labels = pickle.load(handle)\n",
    "\n",
    "gan_data = []\n",
    "    \n",
    "for img_id, label in gan_labels.items():\n",
    "    img_filename = \"{}.jpg\".format(img_id)\n",
    "    img_path = base_path + img_filename\n",
    "    img_row = {}\n",
    "    img_row[\"Path\"] = img_path\n",
    "    img_row[\"Sex\"] = \"Female\"\n",
    "    img_row[\"Age\"] = 21\n",
    "    img_row[\"Frontal/Lateral\"] = \"Frontal\"\n",
    "    img_row[\"AP/PA\"] = \"AP\"\n",
    "    for i, name in enumerate(names):\n",
    "        img_row[name] = label[i]\n",
    "    img_row[\"ID\"] = patient_id\n",
    "    gan_data.append(img_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_df = pd.DataFrame(gan_data)\n",
    "full_train_df = pd.concat([train, gan_df], ignore_index=True)\n",
    "full_train_df.to_csv(path + \"train_preprocessed_subset_1_with_gan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1) For each label vector choose one class, bring them to uniform distribution\n",
    "2) Pick a category and target number\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
