{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "import torch.nn.functional as func\n",
    "import torchxrayvision as xrv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "import random\n",
    "import logging\n",
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/\"\n",
    "train = pd.read_csv(path + \"train_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>...</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173223</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient40439/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103369</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient24820/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>69</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55913</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient13550/study3/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192326</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient46406/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185864</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient44121/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201386</th>\n",
       "      <td>27122</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient06606/study2/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>78</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201387</th>\n",
       "      <td>124987</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient29924/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>84</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201388</th>\n",
       "      <td>211800</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient56212/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>90</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201389</th>\n",
       "      <td>130616</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient31303/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201390</th>\n",
       "      <td>64817</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient15602/study2/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>88</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201391 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               Path     Sex  \\\n",
       "0           173223  CheXpert-v1.0-small/train/patient40439/study1/...  Female   \n",
       "1           103369  CheXpert-v1.0-small/train/patient24820/study2/...  Female   \n",
       "2            55913  CheXpert-v1.0-small/train/patient13550/study3/...  Female   \n",
       "3           192326  CheXpert-v1.0-small/train/patient46406/study1/...  Female   \n",
       "4           185864  CheXpert-v1.0-small/train/patient44121/study1/...    Male   \n",
       "...            ...                                                ...     ...   \n",
       "201386       27122  CheXpert-v1.0-small/train/patient06606/study2/...    Male   \n",
       "201387      124987  CheXpert-v1.0-small/train/patient29924/study1/...  Female   \n",
       "201388      211800  CheXpert-v1.0-small/train/patient56212/study2/...  Female   \n",
       "201389      130616  CheXpert-v1.0-small/train/patient31303/study1/...    Male   \n",
       "201390       64817  CheXpert-v1.0-small/train/patient15602/study2/...    Male   \n",
       "\n",
       "        Age Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  \\\n",
       "0        48         Frontal    AP         0.0                         0.0   \n",
       "1        69         Frontal    PA         0.0                         0.0   \n",
       "2        25         Lateral   NaN         0.0                         0.0   \n",
       "3        45         Frontal    AP         0.0                         0.0   \n",
       "4        51         Frontal    AP         0.0                         0.0   \n",
       "...     ...             ...   ...         ...                         ...   \n",
       "201386   78         Frontal    AP         0.0                         0.0   \n",
       "201387   84         Frontal    AP         0.0                         0.0   \n",
       "201388   90         Frontal    AP         0.0                         0.0   \n",
       "201389   45         Lateral   NaN         0.0                         0.0   \n",
       "201390   88         Frontal    AP         0.0                         0.0   \n",
       "\n",
       "        Cardiomegaly  Lung Opacity  ...  Edema  Consolidation  Pneumonia  \\\n",
       "0                0.0           1.0  ...    0.0            0.0        0.0   \n",
       "1                0.0           0.0  ...    0.0            1.0        0.0   \n",
       "2                0.0           0.0  ...    0.0            0.0        0.0   \n",
       "3                0.0           1.0  ...    0.0            0.0        0.0   \n",
       "4                0.0           0.0  ...    0.0            1.0        0.0   \n",
       "...              ...           ...  ...    ...            ...        ...   \n",
       "201386           0.0           1.0  ...    0.0            1.0        1.0   \n",
       "201387           1.0           1.0  ...    0.0            0.0        0.0   \n",
       "201388           0.0           0.0  ...    1.0            0.0        0.0   \n",
       "201389           0.0           0.0  ...    0.0            1.0        0.0   \n",
       "201390           0.0           0.0  ...    0.0            0.0        0.0   \n",
       "\n",
       "        Atelectasis  Pneumothorax  Pleural Effusion  Pleural Other  Fracture  \\\n",
       "0               0.0           0.0               0.0            0.0       0.0   \n",
       "1               0.0           0.0               0.0            0.0       0.0   \n",
       "2               0.0           0.0               0.0            1.0       0.0   \n",
       "3               0.0           0.0               0.0            0.0       0.0   \n",
       "4               1.0           0.0               0.0            0.0       0.0   \n",
       "...             ...           ...               ...            ...       ...   \n",
       "201386          1.0           0.0               0.0            0.0       0.0   \n",
       "201387          1.0           0.0               0.0            0.0       0.0   \n",
       "201388          1.0           0.0               1.0            0.0       0.0   \n",
       "201389          0.0           0.0               0.0            0.0       0.0   \n",
       "201390          0.0           0.0               0.0            0.0       0.0   \n",
       "\n",
       "        Support Devices     ID  \n",
       "0                   1.0  40439  \n",
       "1                   0.0  24820  \n",
       "2                   0.0  13550  \n",
       "3                   0.0  46406  \n",
       "4                   1.0  44121  \n",
       "...                 ...    ...  \n",
       "201386              0.0   6606  \n",
       "201387              1.0  29924  \n",
       "201388              1.0  56212  \n",
       "201389              0.0  31303  \n",
       "201390              1.0  15602  \n",
       "\n",
       "[201391 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Get data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/om/user/shobhita/src/chexpert/data/CheXpert-v1.0-small/\"\n",
    "def load_data():\n",
    "    # add data augmentations transforms here\n",
    "    transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                                xrv.datasets.XRayResizer(224)])\n",
    "    # replace the paths for the dataset here\n",
    "    d_chex_train = xrv.datasets.CheX_Dataset(imgpath=path,\n",
    "                                       csvpath=path + \"train_preprocessed.csv\",\n",
    "                                       transform=transform,views=[\"PA\", \"AP\"], unique_patients=False)\n",
    "    d_chex_test = xrv.datasets.CheX_Dataset(imgpath=path,\n",
    "                                       csvpath=path + \"test_train_preprocessed.csv\",\n",
    "                                       transform=transform,views=[\"PA\", \"AP\"], unique_patients=False)\n",
    "    return d_chex_train, d_chex_test\n",
    "\n",
    "def get_model():\n",
    "    model = xrv.models.DenseNet(num_classes=13)\n",
    "    print(model.classifier)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    for idx, data in enumerate(dataset):\n",
    "        data['lab']=np.nan_to_num(data['lab'],0)\n",
    "        data['lab']=np.where(data['lab']==-1, 1, data['lab']) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,num_epochs,path_trained_model,train_loader,valid_loader):\n",
    "    print(\"training\")\n",
    "    # hyperparameters\n",
    "    criterion = nn.BCEWithLogitsLoss() \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    best_valid_loss=10000\n",
    "    PATH = path_trained_model\n",
    "    \n",
    "    # going through epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # training loss\n",
    "        print(\"epoch\",epoch)\n",
    "        model.train()\n",
    "        model.to(\"cuda:0\")\n",
    "        train_loss = 0\n",
    "        count=0\n",
    "        for data_all in train_loader:\n",
    "            data=data_all['img']\n",
    "            target=data_all['lab']\n",
    "            count+=1\n",
    "            if count % 100 == 0:\n",
    "                print(\"data \", count)\n",
    "            data = data.to(\"cuda:0\")\n",
    "            target = target.to(\"cuda:0\")\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # validation loss\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data_all in valid_loader:\n",
    "                data=data_all['img']\n",
    "                target=data_all['lab']\n",
    "                data = data.to(\"cuda:0\")\n",
    "                target = target.to(\"cuda:0\")\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target) \n",
    "                valid_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        valid_loss /= len(valid_loader)\n",
    "        \n",
    "        # saves best epoch\n",
    "        print(f'Epoch: {epoch+1}/{num_epochs}.. Training loss: {train_loss}.. Validation Loss: {valid_loss}')\n",
    "        if valid_loss < best_valid_loss:\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            best_valid_loss=valid_loss\n",
    "        print(\"Best Valid Loss so far:\", best_valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAUROC(dataGT, dataPRED, classCount):\n",
    "        \n",
    "    outAUROC = []\n",
    "        \n",
    "    datanpGT = dataGT.cpu().numpy()\n",
    "    datanpPRED = dataPRED.cpu().numpy()\n",
    "        \n",
    "    for i in range(classCount):\n",
    "        try:\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return outAUROC\n",
    "\n",
    "def testing(model, test_loader, nnClassCount, class_names):\n",
    "    if use_gpu:\n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "    model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data_all in tqdm(enumerate(test_loader)):\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(batch_idx)\n",
    "            \n",
    "            data=data_all['img']\n",
    "            target=data_all['lab']\n",
    "            target = target.cuda()\n",
    "            data = data.to(\"cuda:0\")\n",
    "            outGT = torch.cat((outGT, target), 0).cuda()\n",
    "\n",
    "            #bs, c, h, w = data.size()\n",
    "            #varInput = data.view(-1, c, h, w)\n",
    "            \n",
    "            out = model(data)\n",
    "            outPRED = torch.cat((outPRED, out), 0)\n",
    "    aurocIndividual = computeAUROC(outGT, outPRED, nnClassCount)\n",
    "    aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "    print ('AUROC mean ', aurocMean)\n",
    "        \n",
    "    for i in range (0, len(aurocIndividual)):\n",
    "        print (class_names[i], ' ', aurocIndividual[i])\n",
    "        \n",
    "    return outGT, outPRED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting XRayResizer engine to cv2 could increase performance.\n"
     ]
    }
   ],
   "source": [
    "train,test=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172214"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting XRayResizer engine to cv2 could increase performance.\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                                xrv.datasets.XRayResizer(224)])\n",
    "d_chex_train = xrv.datasets.CheX_Dataset(imgpath=path,\n",
    "                                       csvpath=path + \"train.csv\",\n",
    "                                       transform=transform,views=[\"PA\", \"AP\"], unique_patients=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191010"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_chex_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trBatchSize=32\n",
    "datasetTest, datasetTrain = random_split(train, [500, len(train) - 500])  \n",
    "dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=24, pin_memory=True)\n",
    "dataLoaderVal = DataLoader(dataset=datasetValid, batch_size=trBatchSize, shuffle=False, num_workers=24, pin_memory=True)\n",
    "dataLoaderTest = DataLoader(dataset=datasetTest, num_workers=24, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1024, out_features=13, bias=True)\n",
      "training\n",
      "epoch 0\n",
      "data  100\n",
      "data  200\n",
      "data  300\n",
      "data  400\n",
      "data  500\n",
      "data  600\n",
      "Epoch: 1/2.. Training loss: 0.4020114891837088.. Validation Loss: 0.24762111902236938\n",
      "Best Valid Loss so far: 0.24762111902236938\n",
      "epoch 1\n",
      "data  100\n",
      "data  200\n",
      "data  300\n",
      "data  400\n",
      "data  500\n",
      "data  600\n",
      "Epoch: 2/2.. Training loss: 0.3808065941364191.. Validation Loss: 0.24135379493236542\n",
      "Best Valid Loss so far: 0.24135379493236542\n"
     ]
    }
   ],
   "source": [
    "model=get_model()\n",
    "training(model=model,num_epochs=2,path_trained_model=\"densenet_model\",train_loader=dataLoaderTrain,valid_loader=dataLoaderVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faba0b33d1a4f49bb9f4123786eb40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "AUROC mean  0.6153491351471989\n",
      "Enlarged Cardiomediastinum   0.6704626009009628\n",
      "Cardiomegaly   0.6818390804597702\n",
      "Lung Opacity   0.6442086648983202\n",
      "Lung Lesion   0.7087035771246297\n",
      "Edema   0.5763769698860977\n",
      "Consolidation   0.503578947368421\n",
      "Pneumonia   0.488328401672068\n",
      "Atelectasis   0.6266213921901528\n",
      "Pneumothorax   0.732669550959126\n",
      "Pleural Effusion   0.561584840654608\n",
      "Pleural Other   0.5930181175430844\n",
      "Fracture   0.5623404255319149\n",
      "Support Devices   0.6498061877244299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 0.]], device='cuda:0'),\n",
       " tensor([[-1.6123, -2.3601, -2.0904,  ..., -2.1116, -2.7364, -1.6877],\n",
       "         [-1.7371, -2.3061, -2.1212,  ..., -2.1768, -2.9851, -1.7004],\n",
       "         [-1.0029, -1.8266, -1.7144,  ..., -1.9648, -2.6303, -1.4148],\n",
       "         ...,\n",
       "         [-1.4946, -2.0531, -1.9153,  ..., -1.9167, -2.6913, -1.6776],\n",
       "         [-1.8068, -2.3387, -2.1711,  ..., -2.1820, -2.8148, -1.7631],\n",
       "         [-0.8649, -1.7069, -1.5956,  ..., -1.8459, -2.5626, -1.2829]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=['Enlarged Cardiomediastinum', 'Cardiomegaly',\n",
    "       'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
    "       'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other',\n",
    "       'Fracture', 'Support Devices']\n",
    "testing(model, dataLoaderTest, len(class_names), class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
